# LLM-Latency-Lens Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Anthropic API Key
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-...

# Google (Vertex AI) API Key
# Get from: https://console.cloud.google.com/apis/credentials
GOOGLE_API_KEY=...

# =============================================================================
# Application Configuration
# =============================================================================

# Rust logging level (error, warn, info, debug, trace)
RUST_LOG=info

# Enable Rust backtraces (0=off, 1=on, full=full traces)
RUST_BACKTRACE=1

# =============================================================================
# Prometheus Configuration
# =============================================================================

# Prometheus bind host
PROMETHEUS_HOST=0.0.0.0

# Prometheus bind port
PROMETHEUS_PORT=9090

# =============================================================================
# Grafana Configuration
# =============================================================================

# Grafana admin username
GF_ADMIN_USER=admin

# Grafana admin password (CHANGE IN PRODUCTION!)
GF_ADMIN_PASSWORD=change_me_in_production

# Grafana root URL (for production with reverse proxy)
GF_ROOT_URL=http://localhost:3000

# =============================================================================
# TLS/SSL Configuration (Production)
# =============================================================================

# Let's Encrypt email for certificate generation
ACME_EMAIL=your-email@example.com

# =============================================================================
# Alert Configuration
# =============================================================================

# Slack webhook URL for alerts
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK

# =============================================================================
# Database Configuration (Optional)
# =============================================================================

# PostgreSQL connection string (if using database backend)
# DATABASE_URL=postgresql://user:password@localhost:5432/llm_metrics

# =============================================================================
# Observability Configuration (Optional)
# =============================================================================

# OpenTelemetry endpoint
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# OpenTelemetry service name
# OTEL_SERVICE_NAME=llm-latency-lens

# =============================================================================
# Rate Limiting Configuration (Optional)
# =============================================================================

# Maximum requests per second
# MAX_RPS=100

# Burst size for rate limiter
# BURST_SIZE=10

# =============================================================================
# Retry Configuration (Optional)
# =============================================================================

# Maximum retry attempts
# MAX_RETRIES=3

# Retry delay in milliseconds
# RETRY_DELAY_MS=1000

# =============================================================================
# Timeout Configuration (Optional)
# =============================================================================

# Request timeout in seconds
# REQUEST_TIMEOUT_SECONDS=30

# Connection timeout in seconds
# CONNECT_TIMEOUT_SECONDS=10
